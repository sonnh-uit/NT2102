\chapter{Thực nghiệm và đánh giá}
\label{chapter4}
\section{Triển khai}
%chi tiet ve cach lap trinh, cai dat
Công cụ được triển khai bằng Python cho thiết lập luồng A3C và TensorFlow và Keras cho việc triển khai học máy. Để thu thập thông tin về mục tiêu, chúng tôi sử dụng API RPC của Metasploit và Nmap thông qua msfconsole. Kết quả quét được trả về và lưu trong một tệp .xml.

Sau khi thu thập thông tin để xác định hệ thống mục tiêu, agent RL tool lấy danh sách các mô-đun và payload từ Metasploit để exploit qua RPC API. Kết quả exploit được lưu trong tệp .csv để sử dụng cho lần exploit tiếp theo. Các mô-đun trong Metasploit mà agent RL chọn có loại xếp hạng là: xuất sắc, tuyệt vời, tốt. Tiếp theo, agent RL tạo ra danh sách các mô-đun, payload và target với từng dịch vụ đã được liệt kê trong file .xml. Sau đó, các loại thông tin này được sử dụng để huấn luyện RL agent để học cách tự động exploit các dịch vụ đó trong tương lai.

Mạng neural sâu để huấn luyện RL agent được thiết kế với các thiết lập sau: 
\begin{itemize}
    \item Input layer: Lớp này có 5 đơn vị, đại diện cho 5 thuộc tính trạng thái.
    \item Hidden layers: Số lượng lớp ẩn và các đơn vị tương ứng được tùy chỉnh cho các kịch bản thí nghiệm.
    \item Output layer: Nó bao gồm 556 đơn vị, đại diện cho 556 tải trọng khác nhau để khai thác.
\end{itemize}

Trong đó, hàm kích hoạt giữa các lớp ẩn và lớp đầu vào là \textit{relu}. Bên cạnh đó, hàm \textit{softmax} được sử dụng để chỉ ra payload nào trong tập output nên được chọn, tương ứng với mỗi môi trường của target.

Các thông số để huấn luyện agent RL được thể hiện trong \textbf{Bảng \ref{tab:a3c_parameter}}.

\begin{table}[!h]
    \centering
    \caption{Các tham số cho thuật toán học tăng cường}
    \label{tab:a3c_parameter}
    \begin{tabular}{|c|c|}
    \hline
    \textbf{Parameter}      & \textbf{Value} \\ 
    \hline
    Gamma                   & 0.99  \\ 
    \hline
    Epsilon greedy start    & 0.5   \\ 
    \hline
    Epsilon greedy stop     & 0     \\ 
    \hline
    RMSprop learning rate   & 0.005 \\ 
    \hline
    RMSProp decay           & 0.99  \\ 
    \hline
    Loss coefficient        & 0.5   \\ 
    \hline
    Loss entropy   coefficient & 0.01  \\ 
    \hline
    Number of test   worker    & 1     \\ 
    \hline
    Greedy rate                & 0.8   \\ 
    \hline
    \end{tabular}
\end{table}



\section{Môi trường thí nghiệm}

Như các máy chủ huấn luyện, chúng tôi sử dụng 5 máy ảo (VM) Metasploitable2. Ngoài ra, chúng tôi cài đặt 5 VM chạy hệ điều hành Kali Linux, như được hiển thị trong Bảng \textbf{\ref{tab:VM_TB}}. Công cụ dựa trên RL sau đó được cài đặt trên mỗi VM. Nó cũng thay đổi các tham số DRL tương ứng với các kịch bản thử nghiệm, được liệt kê trong Bảng \textbf{\ref{tab:NN_TB}} và Bảng \textbf{\ref{tab:Thread_Trial}}. \\

\begin{table}[!h]
    \centering
    \caption{Cấu hình máy ảo}
    \label{tab:VM_TB}
    \begin{tabular}{|c|c|c|c|} \hline
        \textbf{Name of VMs} &\textbf{Operating System} &\textbf{RAM} &\textbf{CPU} \\ 
        \hline
         Penetration Testing &Kali Linux &12 GB &4 cores \\ 
         \hline
        Testing Server &Ubuntu 18.04 &12 GB &4 cores \\ 
        \hline
    \end{tabular}
    
\end{table}


\begin{table}[!h]
    \centering
    \caption{Danh sách các dịch vụ chứa lỗ hổng trong môi trường thử nghiệm.}
    \label{tab:ServiceTB}
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{Service}     & \textbf{Port}  & \textbf{Operating System}  & \textbf{CVE}  \\ 
    \hline
    Samba       & 445   & Docker Ubuntu  & CVE-2017-7494      \\ 
    \hline
    WebLogic    & 7001  & Docker Ubuntu  & CVE-2017-10271      \\ 
    \hline
    PostgreSQL  & 5432  & Docker Ubuntu  & CVE-2019-9193     \\ 
    \hline
    Supervisor  & 9001  & Docker Ubuntu  & CVE-2017-11610    \\ 
    \hline
    \end{tabular}
\end{table}

Bên cạnh đó, như một máy chủ thử nghiệm, chúng tôi sử dụng 5 máy ảo chạy hệ điều hành Ubuntu 18.04 với cấu hình được hiển thị trong Bảng \textbf{\ref{tab:VM_TB}}. Tất cả các dịch vụ có lỗ hổng được liệt kê trong Bảng \textbf{\ref{tab:ServiceTB}} tồn tại trên mỗi máy ảo.

\section{Kịch bản thí nghiệm}

Để đánh giá hiệu quả của kiểm thử tự động dựa trên RL agent, nhóm nghiên cứu và thí nghiệm để so sánh với phương pháp kiểm thử ngẫu nhiên. Các chỉ số đánh giá bao gòm:

\begin{itemize}
    \item Tỷ lệ thành công của các cuộc khai thác (Total training time).
    \item Tỷ lệ thành công của các cuộc khai thác (The success rate of exploits).
    \item Số bước mà RL agent phải thực hiện để chọn payload khai thác thành công (The number of steps the RL agent must take to select a successful exploit payload).
\end{itemize}

Trong đề tài này, lớp đầu vào đại diện cho số lượng thuộc tính trạng thái, trong khi lớp đầu ra tương ứng với hành động được thực hiện bởi RL agent. Do đó, chúng đều có kích thước cố định. Việc đánh giá sẽ dựa vào thay đổi số lượng lớp của mạng neural. Mặc dù các lớp này không tương tác trực tiếp với môi trường bên ngoài, chúng có ảnh hưởng đáng kể đến đầu ra cuối cùng. Số lượng lớp ẩn và các đơn vị trong mỗi lớp ẩn phải được xem xét cẩn thận \cite{heaton2008introduction}. Under-fitting \cite{jabbar2015methods} sẽ xuất hiện nếu sử dụng quá ít đơn vị cho các lớp ẩn. Sử dụng quá nhiều đơn vị cho các lớp ẩn sẽ dẫn đến quá tải và làm tăng thời gian huấn luyện của mô hình mạng. Cân nhắc các yếu tố này, việc xác định số lượng các đơn vị trong lớp ẩn được thực hiện theo các quy tắng sau: 
\begin{itemize}
    \item Số lượng đơn vị trong mỗi lớp ẩn phải nằm giữa kích thước của lớp đầu vào và lớp đầu ra. 
    \item Số lượng đơn vị trong lớp ẩn nên bằng 2/3 tổng kích thước của (lớp đầu vào + lớp đầu ra). 
\end{itemize}

Tiếp theo, chúng tôi tiến hành thí nghiệm với các cấu hình mạng neural khác nhau để tìm mạng neural tốt nhất để chọn các hành động thích hợp. Các mạng neural được thiết kế với số lượng lớp ẩn khác nhau, như được hiển thị trong Bảng \textbf{\ref{tab:NN_TB}}.  Ngoài ra, để so sánh, chúng tôi thay đổi số luồng công việc và số lần thử tối đa trên tất cả các luồng. Các thiết lập của các luồng và số lần thử nghiệm được minh họa trong Bảng \textbf{\ref{tab:Thread_Trial}}. Chúng tôi tiến hành thay đổi cấu trúc của mạng neural được đề cập ở trên trong tất cả các trường hợp tương ứng với mỗi trường hợp luồng và số lần thử nghiệm. Tiếp theo, chúng tôi huấn luyện công cụ 20 lần trên máy ảo Metasploitable 2 cho mỗi trường hợp trước khi thực hiện thử nghiệm trên máy Ubuntu.

\begin{table}[!t]
    \centering
    \caption{Danh sách các cấu hình mạng thần kinh thử nghiệm}
    \label{tab:NN_TB}
    \begin{tabular}{|m{0.2\textwidth}|m{0.7\textwidth}|}
    \hline
    \textbf{Number of hidden layer} &\textbf{The number of nodes in the hidden layer} \\ 
    \hline
    1 hidden layer &  300                                           \\ 
    \hline
    2 hidden layers & 100 – 300                                     \\ 
    \hline
    4 hidden layers & 50 – 100 – 200 – 400                          \\ 
    \hline
    6 hidden layers & 50 – 100 – 200 – 300 – 400 – 500              \\ 
    \hline
    8 hidden layers & 50 – 100 – 150 – 200 – 250 – 300 – 350 – 400  \\ 
    \hline
    \end{tabular}
\end{table}

\begin{table}[!t]
    \centering
    \caption{Các kịch bản kiểm tra và đào tạo RL với các cài đặt luồng và số lần thử khác nhau}
    \label{tab:Thread_Trial}
    \begin{tabular}{|c|c|c|}
    \hline
    \textbf{Case} & \textbf{Number of threads}     & \textbf{Number of attempts}  \\ 
    \hline
    1   & 20 threads  & 6000 attempts     \\ 
    \hline
    2   & 20 threads  & 10000 attempts    \\ 
    \hline
    3   & 10 threads  & 10000 attempts    \\ 
    \hline
    \end{tabular}
    
\end{table}

\section{Kết quả thực nghiệm}

Chúng tôi thu được các kết quả sau khi thực hiện các kịch bản thử nghiệm:

%\begin{enumerate}
%    \item \textbf{Case 1:} 20 threads and 6000 attempts
\subsection{Trường hợp 1: 20 luồng và 6000 lần thử}

\begin{itemize}
    \item \textbf{Training:} Bảng \textbf{~\ref{tab:training_6000step_20thread}} scho thấy rằng công cụ của chúng tôi có thể khai thác thành công tất cả các dịch vụ đã được chọn trên máy chủ mục tiêu, Metasploitable2. Mặc dù cấu hình mạng neural 1 lớp ẩn mất nhiều thời gian để huấn luyện hơn cấu hình mạng neural 4 lớp ẩn, nhưng cấu hình mạng neural 1 lớp ẩn là hiệu quả nhất về tổng số lần khai thác thành công và lần chọn thành công đầu tiên.  
    \item \textbf{Testing:} Kết quả của thử nghiệm trong Bảng \textbf{\ref{tab:testing_6000step_20thread}} cho thấy rằng công cụ của chúng tôi có thể khai thác thành công tất cả bốn dịch vụ lỗ hổng được cài đặt trong môi trường thí nghiệm của chúng tôi (đối với cấu hình mạng neural 8 lớp ẩn). Với các cấu hình khác như 1 lớp ẩn, 2 lớp ẩn, 4 lớp ẩn hoặc 6 lớp ẩn, tỷ lệ khai thác thành công của công cụ cũng đạt 50\%. Hơn nữa, việc triển khai khai thác đã thành công sau chỉ vài lần thử. Điều này cũng được xem là bằng chứng cho sự ưu việt của công cụ so với phương pháp chọn ngẫu nhiên, vì phương pháp chọn ngẫu nhiên đòi hỏi nhiều lần thử hơn công cụ để khai thác thành công.
\end{itemize}
        
\begin{table}[!h]
    \centering 
    \caption{Kết quả của trường hợp đào tạo với 6000 lần thử và 20 luồng}
    \label{tab:training_6000step_20thread}

    \begin{tabular}{| m{0.14\textwidth}| m{0.14\textwidth}| m{0.18\textwidth}| m{0.19\textwidth}| m{0.1\textwidth}|}
    \hline
    \textbf{Number of hidden layer}     &\textbf{Total training time}   &\textbf{Total exploit service success} &\textbf{Total payload exploit success}  &\textbf{First-choice success}  \\ 
    \hline
    \textbf{1 layer} 	&\textbf{0:41:26}	&\textbf{6}	&\textbf{342}	&\textbf{226}	\\ 
    \hline
    2 layer 	&0:39:21	&6	&297	&159	\\ 
    \hline
    4 layer	&0:39:06	&6	&298	&179	\\ 
    \hline
    6 layer 	&0:52:36	&6	&280	&173	\\ 
    \hline
    8 layer	&0:55:59	&6	&263	&156	\\ \hline
    \end{tabular} 
\end{table}

                
\begin{table}[!h]
    \centering
    \caption{Kết quả khai thác trường hợp 20 luồng và 6000 lần thử trên máy Ubuntu}
    \label{tab:testing_6000step_20thread}
    \begin{tabular}{|p{0.13\textwidth}|p{0.135\textwidth}|p{0.1\textwidth}|p{0.18\textwidth}|p{0.15\textwidth}|p{0.15\textwidth}|}
    % \begin{tabular}{c|c|c|c|c|c}
    \hline
    \textbf{Approach} &\textbf{Number of hidden layer}  &\textbf{Samba}	&\textbf{PostgreSQL}	&\textbf{WebLogic}	&\textbf{Supervisor}  \\ 
    \hline
    RL agent &1 layer	&-	&-	&4	&1	 \\ 
    \hline
    RL agent &2 layer 	&1	&-	&-	&1	 \\ 
    \hline
    RL agent &4 layer 	&-	&2	&-	&2 	\\ 
    \hline
    RL agent &6 layer 	&2	&-	&-	&3	\\ 
    \hline
    \textbf{RL agent} &\textbf{8 layer}	&\textbf{2}	&\textbf{8}	&\textbf{4}	&\textbf{9}	 \\ 
    \hline
    \textbf{Random agent}	&\textbf{-}		&\textbf{149}	&\textbf{25}	&\textbf{13}	&\textbf{30}	 \\ 
    \hline
    \end{tabular}                
\end{table}

\subsection{Trường hợp 2: 20 luồng và 10000 lần thử}

\begin{itemize}
    \item \textbf{Training:} Khi số lần thử trên tổng số luồng công nhân được tăng lên 10000, kết quả huấn luyện trong Bảng \textbf{\ref{tab:training_10000step_20thread}} cho thấy rằng công cụ đã khai thác thành công trên tất cả các cấu trúc mạng neural. Bên cạnh đó, cấu trúc mạng neural với 8 lớp ẩn đem lại hiệu quả học tập ưu việt theo hai chỉ số: tỷ lệ thành công của các khai thác và số bước mà agen RL phải thực hiện để chọn một tải trọng khai thác thành công. Tuy nhiên, so với trường hợp có 20 luồng và 6000 lần thử, thời gian trung bình đã tăng khoảng 5-10 phút. 
    \item \textbf{Testing:} Bảng \textbf{\ref{tab:testing_10000step_20thread}} mô tả khả năng khai thác trong môi trường thử nghiệm khi số lần thử được tăng lên 10000 lần. Công cụ vẫn có khả năng khai thác thành công tất cả các dịch vụ cho cấu hình mạng neural 8 lớp ẩn. Công cụ cũng có khả năng khai thác thành công dịch vụ Samba lần đầu tiên. Hơn nữa, chúng tôi phát hiện rằng tỷ lệ thành công khai thác cho các cấu hình mạng neural còn lại đã tăng từ 50\% lên 75\% trong khi thời gian trung bình tăng khoảng 15 phút.
\end{itemize}

 \begin{table}[!h]
    \centering
    \caption{Kết quả của trường hợp đào tạo với cài đặt 10000 lần thử và 20 luồng}
    \label{tab:training_10000step_20thread}
    \begin{tabular}{|p{0.14\textwidth}| p{0.13\textwidth}| p{0.18\textwidth}| p{0.19\textwidth}| p{0.1\textwidth}|}
    \hline
    \textbf{Number of hidden layer}&\textbf{Total training time}   &\textbf{Total exploit service success} &\textbf{Total payload exploit success}  &\textbf{First-choice success}  \\ 
    \hline
    1 layer 	&1:06:00	&6	&263	&172	\\ 
    \hline
    2 layer 	&1:05:00	&6	&264	&180	\\ 
    \hline
    4 layer	&1:16:00	&6	&266	&188	\\ 
    \hline
    6 layer 	&1:09:00	&6	&337	&221	\\ 
    \hline
    \textbf{8 layer}	&\textbf{1:09:00}	&\textbf{6}	&\textbf{353}	&\textbf{199}	\\ 
    \hline
    \end{tabular} 
\end{table}


\begin{table}[!h]
    \centering
    \caption{Kết quả khai thác trường hợp 20 luồng và 10000 lần thử trên máy Ubuntu}
    \label{tab:testing_10000step_20thread}
    \begin{tabular}{|p{0.13\textwidth}|p{0.135\textwidth}|p{0.1\textwidth}|p{0.18\textwidth}|p{0.15\textwidth}|p{0.15\textwidth}|}
    \hline
    \textbf{Approach} &\textbf{Number of hidden Layer}  &\textbf{Samba}	&\textbf{PostgreSQL}	&\textbf{WebLogic}	&\textbf{Supervisor}  \\ 
    \hline
    RL agent &1 layer	&1	&4	&-	&3	 \\ 
    \hline
    RL agent &2 layer 	&2	&8	&-	&1	 \\ 
    \hline
    RL agent &4 layer 	&1	&1	&-	&1 	\\ 
    \hline
    RL agent &6 layer 	&-	&7	&-	&8	\\ 
    \hline
    \textbf{RL agent} &\textbf{8 layer}	&\textbf{1}	&\textbf{6}	&\textbf{5}	&\textbf{2}	 \\ 
    \hline
    \textbf{Random agent}	&\textbf{-}		&\textbf{149}	&\textbf{25}	&\textbf{13}	&\textbf{30}	 \\ 
    \hline
    \end{tabular}                
\end{table}

\subsection{Trường hợp 3: 10 luồng và 10000 lần thử}
\begin{itemize}
    \item \textbf{Training:} Giảm số lượng luồng công nhân từ 20 xuống 10 đã làm tăng thời gian huấn luyện (khoảng 10 phút trung bình). Kết quả huấn luyện được thể hiện trong Bảng \textbf{\ref{tab:training_10000step_10thread}},  và công cụ vẫn có khả năng khai thác thành công tất cả các dịch vụ trên máy chủ huấn luyện.
    \item \textbf{Testing:} Việc giảm số lượng luồng không ảnh hưởng lớn đến khả năng khai thác các lỗ hổng của công cụ trong chế độ kiểm tra. Bảng \textbf{\ref{tab:testing_10000step_10thread}} cho thấy cho cấu hình mạng neural 8 lớp ẩn, công cụ vẫn có thể khai thác thành công tất cả các dịch vụ trên máy chủ kiểm tra. Công cụ có khả năng thành công ngay lần thử đầu tiên với một số khai thác thành công, đặc biệt là đối với dịch vụ Supervisor.
\end{itemize}

\begin{table}[!h]
    \centering 
    \caption{Kết quả của trường hợp đào tạo với 10000 lần thử và 10 luồng}
    \label{tab:training_10000step_10thread}

    \begin{tabular}{| p{0.14\textwidth}| p{0.13\textwidth}| p{0.18\textwidth}| p{0.19\textwidth}| p{0.1\textwidth}|}
    \hline
    \textbf{Number of hidden layer}     &\textbf{Total training time}   &\textbf{Total exploit service success} &\textbf{Total payload exploit success}  &\textbf{First-choice success}  \\ 
    \hline
    \textbf{1 layer}	&\textbf{1:13:00}	&\textbf{6}	&\textbf{332}  &\textbf{213}	\\ 
    \hline
    2 layer 	&1:17:00	&6	&315	&206	\\ 
    \hline
    4 layer	&1:18:00	&6	&307	&201	\\ 
    \hline
    6 layer 	&1:14:00	&6	&286	&206	\\ 
    \hline
    8 layer	&1:18:00	&6	&282	&206	\\ 
    \hline
    \end{tabular} 

\end{table}

\begin{table}[!t]
    
    \centering
    \caption{Kết quả khai thác trường hợp 10 luồng, 10000 lần thử trên máy Ubuntu}
    \label{tab:testing_10000step_10thread}
    \begin{tabular}{|p{0.13\textwidth}|p{0.135\textwidth}|p{0.1\textwidth}|p{0.18\textwidth}|p{0.15\textwidth}|p{0.15\textwidth}|}
    
    \hline
    \textbf{Approach} &\textbf{Number of hidden layer}  &\textbf{Samba}	&\textbf{PostgreSQL}	&\textbf{WebLogic}	&\textbf{Supervisor}  \\ 
    \hline
    RL agent &1 layer	&2	&-	&9	&6	 \\ 
    \hline
    RL agent &2 layer 	&4	&-	&7	&4	 \\ 
    \hline
    RL agent &4 layer 	&4	&-	&-	&7 	\\ 
    \hline
    RL agent &6 layer 	&1	&4	&-	&5	\\ 
    \hline
    \textbf{RL agent} &\textbf{8 layer}	&\textbf{5}	&\textbf{6}	&\textbf{8}	&\textbf{1}	 \\ 
    \hline
    \textbf{Random agent}	&\textbf{-}		&\textbf{149}	&\textbf{25}	&\textbf{13}	&\textbf{30}	 \\ 
    \hline
    \end{tabular} 
\end{table}

%             \end{itemize}
% \end{enumerate}
% %
Nhìn chung, phương pháp dựa trên DRL cho kiểm thử xâm nhập có khả năng khai thác thành công tất cả các dịch vụ có lỗ hổng trong môi trường kiểm tra. Để thử nghiệm trên môi trường thực nghiệm chứa các lỗ hổng, cấu hình mạng neural với 8 lớp ẩn đạt hiệu suất và sự ổn định tốt hơn cho công cụ. Mặc dù việc tăng số lượng lớp ẩn và số nút trong mỗi lớp cũng làm tăng thời gian huấn luyện mô hình, kết quả luôn đạt 100\% khai thác thành công các dịch vụ đã cho.